# üìä Framework de Avalia√ß√£o - Assistente Jur√≠dico PJe

Sistema completo de avalia√ß√£o autom√°tica para os 15 agentes de IA jur√≠dicos.

## üéØ Vis√£o Geral

Este framework avalia a performance dos agentes em 3 m√©tricas cr√≠ticas:

1. **Precis√£o de An√°lise de Intima√ß√µes** (Mrs. Justin-e)
2. **Qualidade de Reda√ß√£o de Peti√ß√µes** (redacao-peticoes)
3. **Precis√£o de C√°lculo de Prazos** (gestao-prazos)

## üìÅ Estrutura de Arquivos

```
data/evaluation/
‚îú‚îÄ‚îÄ README.md                    # Este arquivo
‚îú‚îÄ‚îÄ test-queries.json            # 30 queries de teste (10 por m√©trica)
‚îú‚îÄ‚îÄ test-responses.json          # Respostas coletadas dos agentes
‚îî‚îÄ‚îÄ evaluation-report.json       # Relat√≥rio de avalia√ß√£o (gerado)

scripts/evaluation/
‚îú‚îÄ‚îÄ run-agent-evaluation.cjs     # Runner que coleta respostas dos agentes
‚îî‚îÄ‚îÄ evaluate_agents.py           # Script Python que calcula m√©tricas
```

## üöÄ Como Usar

### 1. Coletar Respostas dos Agentes

```bash
# Executar runner que chama os agentes com queries de teste
npm run eval:run

# Sa√≠da esperada:
# ‚úÖ 30/30 respostas coletadas
# üíæ Salvo em: data/evaluation/test-responses.json
```

### 2. Avaliar Performance

```bash
# Executar avalia√ß√£o completa com Python
npm run eval:analyze

# Ou com par√¢metros customizados:
python scripts/evaluation/evaluate_agents.py \
  --queries data/evaluation/test-queries.json \
  --responses data/evaluation/test-responses.json \
  --output data/evaluation/evaluation-report.json
```

### 3. Executar Pipeline Completo

```bash
# Coleta + Avalia√ß√£o em um comando
npm run eval:full
```

## üìä M√©tricas Detalhadas

### 1Ô∏è‚É£ Precis√£o de An√°lise de Intima√ß√µes

**Agente**: `justine` (Mrs. Justin-e)

**Campos Avaliados**:

- `tipo` - Classifica√ß√£o do tipo de intima√ß√£o (string)
- `prazo` - Prazo identificado (string, ex: "15 dias")
- `dataLimite` - Data limite calculada (ISO 8601 ou null)
- `urgencia` - N√≠vel de urg√™ncia (cr√≠tica|alta|normal|baixa)
- `requerManifestacao` - Se requer resposta (boolean)

**C√°lculo de Accuracy**:

```
Accuracy = (acertos_tipo + acertos_prazo + acertos_dataLimite + acertos_urgencia + acertos_manifestacao) / 5
```

**Exemplo de Query**:

```json
{
  "id": "intimacao_001",
  "metric": "Precis√£o de An√°lise de Intima√ß√µes",
  "input": {
    "texto": "Fica a parte INTIMADA para apresentar CONTESTA√á√ÉO no prazo de 15 dias...",
    "dataPublicacao": "2024-12-01"
  },
  "expected_output": {
    "tipo": "Contesta√ß√£o",
    "prazo": "15 dias",
    "dataLimite": "2024-12-20",
    "urgencia": "normal",
    "requerManifestacao": true
  }
}
```

### 2Ô∏è‚É£ Qualidade de Reda√ß√£o de Peti√ß√µes

**Agente**: `redacao-peticoes`

**Campos Avaliados**:

- `estrutura` - Array de se√ß√µes presentes (m√≠nimo 4 esperado)
- `fundamentacaoJuridica` - Fundamenta√ß√£o presente (boolean)
- `citacaoLegislacao` - Cita√ß√µes legais adequadas (boolean)
- `jurisprudencia` - Refer√™ncias a precedentes (boolean)
- `petitosClaros` - Pedidos objetivos (boolean)
- `linguagemFormal` - Linguagem t√©cnica adequada (boolean)

**C√°lculo de Accuracy**:

```
Accuracy = m√©dia de acertos nos 6 campos
```

**Exemplo de Query**:

```json
{
  "id": "peticao_001",
  "metric": "Qualidade de Reda√ß√£o de Peti√ß√µes",
  "input": {
    "tipo": "Peti√ß√£o Inicial",
    "assunto": "A√ß√£o de Cobran√ßa",
    "detalhes": "Cliente prestou servi√ßos no valor de R$ 50.000,00..."
  },
  "expected_output": {
    "estrutura": ["Qualifica√ß√£o", "Fatos", "Direito", "Pedidos"],
    "fundamentacaoJuridica": true,
    "citacaoLegislacao": true,
    "jurisprudencia": true,
    "petitosClaros": true,
    "linguagemFormal": true
  }
}
```

### 3Ô∏è‚É£ Precis√£o de C√°lculo de Prazos

**Agente**: `gestao-prazos`

**Campos Avaliados**:

- `dataLimite` - Data final calculada (ISO 8601)
- `diasCorridos` - N√∫mero de dias corridos (number)
- `diasUteis` - N√∫mero de dias √∫teis (number ou null)
- `feriadosNoIntervalo` - Lista de feriados detectados (array)
- `alertas` - Avisos relevantes (array)

**C√°lculo de Accuracy**:

```
Accuracy = (acertos_dataLimite + acertos_diasCorridos + acertos_diasUteis + acertos_feriados + acertos_alertas) / 5
```

**Exemplo de Query**:

```json
{
  "id": "prazo_001",
  "metric": "Precis√£o de C√°lculo de Prazos",
  "input": {
    "prazo": "15 dias",
    "dataInicio": "2024-12-01",
    "tipo": "dias corridos"
  },
  "expected_output": {
    "dataLimite": "2024-12-16",
    "diasCorridos": 15,
    "diasUteis": null,
    "feriadosNoIntervalo": [],
    "alertas": []
  }
}
```

## üìà Interpreta√ß√£o de Resultados

### Scores de Accuracy

| Faixa   | Interpreta√ß√£o             | A√ß√£o Recomendada            |
| ------- | ------------------------- | --------------------------- |
| 90-100% | ‚úÖ Excelente              | Manter monitoramento        |
| 70-90%  | ‚ö†Ô∏è Bom, mas pode melhorar | Revisar casos de erro       |
| 50-70%  | üî¥ Abaixo do esperado     | Refatorar l√≥gica do agente  |
| <50%    | ‚ùå Cr√≠tico                | Revis√£o completa necess√°ria |

### Exemplo de Relat√≥rio

```json
{
  "timestamp": "2024-12-13T10:30:00Z",
  "total_queries": 30,
  "overall_accuracy": 0.85,
  "metric_results": [
    {
      "metric_name": "Precis√£o de An√°lise de Intima√ß√µes",
      "agent_id": "justine",
      "accuracy": 0.92,
      "precision": 0.92,
      "recall": 0.92,
      "f1_score": 0.92,
      "detailed_scores": {
        "accuracy_tipo": 0.95,
        "accuracy_prazo": 0.9,
        "accuracy_dataLimite": 0.88,
        "accuracy_urgencia": 0.93,
        "accuracy_manifestacao": 0.94
      }
    }
  ],
  "recommendations": [
    "‚úÖ justine: Excelente performance (92%)!",
    "üîç justine: Focar em melhorar: accuracy_dataLimite"
  ]
}
```

## üîß Customiza√ß√µes

### Adicionar Nova Query

Editar `test-queries.json`:

```json
{
  "id": "intimacao_011",
  "metric": "Precis√£o de An√°lise de Intima√ß√µes",
  "input": {
    "texto": "...",
    "dataPublicacao": "..."
  },
  "expected_output": {
    "tipo": "...",
    "prazo": "..."
  }
}
```

### Adicionar Nova M√©trica

1. **Criar Avaliador** em `evaluate_agents.py`:

```python
class NovaMetricaEvaluator:
    def __init__(self):
        self.metric_name = "Nome da Nova M√©trica"
        self.agent_id = "id-do-agente"

    def evaluate(self, responses: List[Dict]) -> MetricResult:
        # Implementar l√≥gica de avalia√ß√£o
        pass
```

2. **Registrar Avaliador**:

```python
# Em AgentEvaluationFramework.__init__
self.evaluators.append(NovaMetricaEvaluator())
```

3. **Adicionar Queries** para nova m√©trica em `test-queries.json`

### Alterar Limites de Accuracy

Em `evaluate_agents.py`, fun√ß√£o `_generate_recommendations`:

```python
if result.accuracy < 0.7:  # Alterar para 0.8 se quiser ser mais rigoroso
    recommendations.append("‚ö†Ô∏è Accuracy baixa...")
```

## üêõ Troubleshooting

### Erro: "ModuleNotFoundError: No module named 'json'"

Voc√™ precisa ter Python 3.8+ instalado:

```bash
python --version  # Deve ser 3.8 ou superior
```

### Erro: "FileNotFoundError: test-queries.json not found"

Execute o comando a partir da raiz do projeto:

```bash
cd c:\Users\thiag\OneDrive\Documentos\GitHub\assistente-jur-dico-principal\.git\assistente-jur-dico-principal
npm run eval:analyze
```

### Agent Runner falha ao executar

Verificar se o servidor de desenvolvimento est√° rodando:

```bash
npm run dev
```

Ou executar apenas com mocks (padr√£o):

```bash
npm run eval:run  # Usa respostas simuladas
```

## üìö Pr√≥ximos Passos

- [ ] Adicionar visualiza√ß√µes (gr√°ficos) ao relat√≥rio
- [ ] Integrar com CI/CD para avalia√ß√£o cont√≠nua
- [ ] Criar dashboard web para visualizar resultados
- [ ] Expandir para os outros 12 agentes
- [ ] Implementar compara√ß√£o entre vers√µes de agentes

## ü§ù Contribuindo

Para adicionar novas queries ou m√©tricas:

1. Edite os arquivos JSON apropriados
2. Execute `npm run eval:full` para validar
3. Commit as mudan√ßas se accuracy >= 70%

---

**Documenta√ß√£o**: `docs/EVALUATION_FRAMEWORK.md`  
**Suporte**: Consulte as instru√ß√µes do Copilot em `.github/copilot-instructions.md`
