# üîç Guia de Configura√ß√£o - OpenTelemetry Tracing

## ‚ö° Quick Start (5 minutos)

### 1. Configurar Endpoint OTLP

Edite o arquivo `.env.local`:

```bash
# Desenvolvimento (padr√£o - AI Toolkit)
VITE_OTLP_ENDPOINT=http://localhost:4318/v1/traces
```

### 2. Ativar AI Toolkit Trace Viewer

No VS Code:
1. Pressione `Ctrl+Shift+P` (Windows) ou `Cmd+Shift+P` (Mac)
2. Digite: "AI Toolkit: Open Trace Viewer"
3. Pressione Enter

### 3. Executar o Sistema

```bash
npm run dev
```

### 4. Visualizar Traces

- Navegue no sistema (ex: criar uma minuta, processar intima√ß√£o)
- Volte ao AI Toolkit Trace Viewer
- Veja os traces aparecerem em tempo real! üéâ

---

## üåê Configura√ß√µes para Produ√ß√£o

### Op√ß√£o 1: Azure Monitor (Recomendado para Microsoft Stack)

```bash
# .env.local ou .env.production
VITE_OTLP_ENDPOINT=https://YOUR-REGION.monitor.azure.com/v1/traces
```

**Como obter:**
1. Portal Azure ‚Üí Application Insights
2. Overview ‚Üí Configure OpenTelemetry
3. Copie o endpoint OTLP HTTP

**Benef√≠cios:**
- ‚úÖ Integra√ß√£o nativa com Azure
- ‚úÖ Visualiza√ß√£o de traces no Azure Portal
- ‚úÖ Correla√ß√£o com Application Insights
- ‚úÖ Alertas autom√°ticos

### Op√ß√£o 2: Datadog APM

```bash
VITE_OTLP_ENDPOINT=https://api.datadoghq.com/api/v2/traces
```

**Como configurar:**
1. Datadog Dashboard ‚Üí APM ‚Üí Setup Instructions
2. Habilite "OpenTelemetry Ingestion"
3. Obtenha API Key
4. Configure header `DD-API-KEY` (requer modifica√ß√£o em `otel-integration.ts`)

**Benef√≠cios:**
- ‚úÖ APM robusto com m√©tricas
- ‚úÖ Distributed tracing avan√ßado
- ‚úÖ Dashboards prontos para LLMs
- ‚úÖ Machine learning para anomalias

### Op√ß√£o 3: Honeycomb

```bash
VITE_OTLP_ENDPOINT=https://api.honeycomb.io/v1/traces
```

**Como configurar:**
1. Honeycomb ‚Üí Settings ‚Üí API Keys
2. Crie novo API Key
3. Configure header `X-Honeycomb-Team` (requer modifica√ß√£o)

**Benef√≠cios:**
- ‚úÖ Observabilidade especializada em IA
- ‚úÖ Queries poderosas (BubbleUp, etc.)
- ‚úÖ Excelente para debugging de LLM

### Op√ß√£o 4: Jaeger (Self-Hosted)

```bash
VITE_OTLP_ENDPOINT=http://your-jaeger-host:4318/v1/traces
```

**Como instalar:**
```bash
# Docker Compose
docker run -d --name jaeger \
  -p 16686:16686 \
  -p 4318:4318 \
  jaegertracing/all-in-one:latest
```

**Acesso UI:** http://localhost:16686

**Benef√≠cios:**
- ‚úÖ Totalmente gratuito e open-source
- ‚úÖ Controle total dos dados
- ‚úÖ Sem custos de tr√°fego

---

## üîß Configura√ß√£o Avan√ßada

### Headers Customizados (se necess√°rio)

Edite `src/lib/otel-integration.ts`:

```typescript
// Configurar exportador OTLP
const otlpExporter = new OTLPTraceExporter({
  url: OTLP_ENDPOINT,
  headers: {
    'Content-Type': 'application/json',
    // Adicione headers customizados aqui:
    'X-API-Key': 'sua-api-key', // Datadog, Honeycomb, etc.
    'Authorization': 'Bearer token', // Autentica√ß√£o customizada
  },
  timeoutMillis: 5000,
});
```

### Sampling (Reduzir Volume de Traces)

Para produ√ß√£o com alto tr√°fego:

```typescript
// src/lib/otel-integration.ts
import { TraceIdRatioBasedSampler } from '@opentelemetry/sdk-trace-base';

const tracerProvider = new WebTracerProvider({
  resource,
  sampler: new TraceIdRatioBasedSampler(0.1), // 10% dos traces
});
```

---

## üìä O Que Ser√° Rastreado

### Opera√ß√µes de Agentes
- ‚úÖ Processamento de tarefas
- ‚úÖ Execu√ß√£o de agentes (Harvey, Mrs. Justin-e, etc.)
- ‚úÖ Gera√ß√£o de minutas
- ‚úÖ An√°lise de intima√ß√µes

### Chamadas LLM
- ‚úÖ Requisi√ß√µes ao Gemini 2.5 Pro
- ‚úÖ Tokens usados (prompt + completion)
- ‚úÖ Temperatura e par√¢metros
- ‚úÖ Tempo de resposta

### API Endpoints
- ‚úÖ `/api/agents` - Processamento de agentes
- ‚úÖ `/api/cron` - Jobs agendados
- ‚úÖ `/api/llm-stream` - Streaming LLM

### Eventos Customizados
- ‚úÖ `task.started` - In√≠cio de processamento
- ‚úÖ `task.completed` - Conclus√£o com sucesso
- ‚úÖ `task.failed` - Falha com erro
- ‚úÖ `agent.status.processing` - Mudan√ßa de status

---

## üêõ Troubleshooting

### Traces n√£o aparecem no AI Toolkit

**Solu√ß√£o 1: Verificar se o Trace Viewer est√° aberto**
```
Ctrl+Shift+P ‚Üí "AI Toolkit: Open Trace Viewer"
```

**Solu√ß√£o 2: Verificar endpoint**
```bash
echo $VITE_OTLP_ENDPOINT
# Deve ser: http://localhost:4318/v1/traces
```

**Solu√ß√£o 3: Verificar inicializa√ß√£o**
Abra o Console do navegador e procure:
```
‚úÖ [OpenTelemetry] Inicializado com sucesso
üìä [OpenTelemetry] Endpoint: http://localhost:4318/v1/traces
```

### Erro: "Failed to fetch" ou CORS

**Solu√ß√£o: Usar HTTPS em produ√ß√£o**
```bash
# Produ√ß√£o - sempre HTTPS
VITE_OTLP_ENDPOINT=https://seu-collector.com/v1/traces
```

### Traces n√£o aparecem em produ√ß√£o

**Verificar:**
1. Endpoint est√° acess√≠vel (teste com `curl`)
2. Headers de autentica√ß√£o configurados
3. CORS permitindo origem do app
4. Firewall/proxy n√£o bloqueando porta

---

## üìà M√©tricas e Atributos

### Atributos Padr√£o em Todos os Spans

```typescript
{
  'service.name': 'assistente-juridico-pje',
  'service.version': '1.0.1',
  'deployment.environment': 'production',
  'telemetry.sdk.name': 'opentelemetry',
  'telemetry.sdk.language': 'typescript'
}
```

### Atributos de Agentes

```typescript
{
  'agent.id': 'harvey',
  'agent.name': 'Harvey Specter',
  'task.id': 'uuid',
  'task.type': 'ANALYZE_INTIMATION',
  'task.priority': 'high',
  'processing_time_ms': 1234,
  'tokens_used': 500
}
```

### Atributos de LLM

```typescript
{
  'llm.model': 'gemini-2.5-pro',
  'llm.temperature': 0.7,
  'llm.max_tokens': 4096,
  'llm.prompt_tokens': 250,
  'llm.completion_tokens': 750,
  'llm.total_tokens': 1000,
  'llm.response_time_ms': 2340
}
```

---

## üéØ Pr√≥ximos Passos

1. **Configure o endpoint** no `.env.local`
2. **Ative o Trace Viewer** (Ctrl+Shift+P)
3. **Execute o sistema** (`npm run dev`)
4. **Teste uma opera√ß√£o** (criar minuta, processar intima√ß√£o)
5. **Visualize os traces** em tempo real!

---

## üìö Documenta√ß√£o Adicional

- [OpenTelemetry Docs](https://opentelemetry.io/docs/)
- [AI Toolkit Trace Viewer](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)
- [Azure Monitor OpenTelemetry](https://learn.microsoft.com/azure/azure-monitor/app/opentelemetry-enable)
- [Datadog OpenTelemetry](https://docs.datadoghq.com/tracing/trace_collection/opentelemetry/)

---

**Precisa de ajuda?** Abra uma issue no GitHub ou consulte a documenta√ß√£o em `.github/copilot-instructions.md`
