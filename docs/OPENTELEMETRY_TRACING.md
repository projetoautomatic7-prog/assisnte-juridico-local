# üîç OpenTelemetry Tracing - Assistente Jur√≠dico PJe

## Vis√£o Geral

O sistema de tracing foi configurado com OpenTelemetry para fornecer observabilidade completa das opera√ß√µes dos agentes de IA e chamadas LLM (Gemini). Os traces s√£o exportados para o **AI Toolkit Trace Viewer** da Microsoft, permitindo an√°lise detalhada de performance e debugging.

## üìã O Que Foi Configurado

### 1. Depend√™ncias Instaladas
- `@opentelemetry/api` - API principal do OpenTelemetry
- `@opentelemetry/sdk-trace-web` - SDK para web browsers
- `@opentelemetry/exporter-trace-otlp-http` - Exportador OTLP via HTTP
- `@opentelemetry/resources` - Gest√£o de recursos
- `@opentelemetry/semantic-conventions` - Conven√ß√µes sem√¢nticas padr√£o

### 2. Arquivos Criados/Modificados

#### Novos Arquivos
- **`src/lib/otel-integration.ts`** - Configura√ß√£o e inicializa√ß√£o do OpenTelemetry
  - Inicializa√ß√£o do provider
  - Configura√ß√£o do exportador OTLP
  - Helpers para criar spans
  - Bridge com sistema de tracing existente

#### Arquivos Modificados
- **`src/main.tsx`** - Inicializa√ß√£o do tracing no entry point
- **`src/lib/gemini-service.ts`** - Instrumenta√ß√£o das chamadas LLM
- **`src/hooks/use-autonomous-agents.ts`** - Tracing de opera√ß√µes dos agentes
- **`package.json`** - Depend√™ncias OpenTelemetry
- **`.env.example`** - Vari√°vel `VITE_OTLP_ENDPOINT`

### 3. Sistema de Tracing Existente

O projeto j√° possui um sistema de tracing robusto em `src/lib/tracing.ts` que foi **integrado** com OpenTelemetry, n√£o substitu√≠do. Agora temos:

- **Sistema interno** - Armazena traces em mem√≥ria, console, HTTP
- **OpenTelemetry** - Exporta para ferramentas profissionais (AI Toolkit, Azure Monitor, etc.)
- **Bridge autom√°tica** - Spans criados com `tracingService` s√£o automaticamente enviados ao OpenTelemetry

## üöÄ Como Usar

### 1. Instalar Depend√™ncias

```bash
npm install
```

### 2. Configurar Vari√°vel de Ambiente (Opcional)

O endpoint padr√£o √© `http://localhost:4318/v1/traces` (AI Toolkit local).

Para usar endpoint customizado, adicione ao `.env.local`:

```env
VITE_OTLP_ENDPOINT=https://seu-coletor-otlp.com/v1/traces
```

### 3. Abrir AI Toolkit Trace Viewer

**M√©todo 1: Via Command Palette**
1. Pressione `Ctrl+Shift+P` (Windows/Linux) ou `Cmd+Shift+P` (Mac)
2. Digite: `AI Toolkit: Open Trace Viewer`
3. Pressione Enter

**M√©todo 2: Via Extens√£o**
1. Abra a barra lateral do VS Code
2. Clique no √≠cone do AI Toolkit
3. Navegue at√© "Trace Viewer"

### 4. Iniciar Aplica√ß√£o

```bash
npm run dev
```

O tracing ser√° inicializado automaticamente e voc√™ ver√° no console:

```
‚úÖ [OpenTelemetry] Inicializado com sucesso
üìä [OpenTelemetry] Endpoint: http://localhost:4318/v1/traces
üîç [OpenTelemetry] Abra o AI Toolkit Trace Viewer para visualizar traces
```

### 5. Usar a Aplica√ß√£o

Conforme voc√™ interage com o sistema (processamento de intima√ß√µes, chamadas LLM, opera√ß√µes de agentes), os traces ser√£o automaticamente enviados e aparecer√£o no Trace Viewer.

## üìä O Que Est√° Sendo Rastreado

### 1. Chamadas LLM (Gemini)

Toda chamada ao Gemini gera um span contendo:

**Atributos:**
- `llm.model` - Modelo usado (ex: `gemini-2.5-pro`)
- `llm.operation` - Opera√ß√£o (ex: `generateContent`)
- `llm.temperature` - Temperatura usada
- `llm.max_tokens` - M√°ximo de tokens
- `llm.prompt_tokens` - Tokens do prompt
- `llm.completion_tokens` - Tokens da resposta
- `llm.total_tokens` - Total de tokens
- `llm.response_time_ms` - Tempo de resposta

**Eventos:**
- In√≠cio da chamada
- Resposta recebida
- Erros (se houver)

### 2. Opera√ß√µes de Agentes

Cada tarefa executada por um agente gera um span contendo:

**Atributos:**
- `agent.id` - ID do agente (ex: `harvey`, `justine`)
- `agent.name` - Nome amig√°vel do agente
- `task.id` - ID da tarefa
- `task.type` - Tipo da tarefa
- `task.priority` - Prioridade da tarefa
- `task.status` - Status (completed, failed)
- `task.duration_ms` - Dura√ß√£o em milissegundos
- `task.tokens_used` - Tokens consumidos (se aplic√°vel)
- `execution.mode` - Modo de execu√ß√£o (hybrid, streaming, traditional)
- `hybrid.mode_used` - Se h√≠brido, qual modo foi usado (langGraph, traditional)

**Eventos:**
- `task.started` - Tarefa iniciada
- `execution.mode.selected` - Modo de execu√ß√£o selecionado
- `task.completed` - Tarefa conclu√≠da
- `task.error` - Erro durante execu√ß√£o (se houver)

### 3. Contexto Distribu√≠do

Traces relacionados compartilham o mesmo `traceId`, permitindo rastrear opera√ß√µes complexas:

```
Trace ID: abc123...
‚îú‚îÄ‚îÄ Span: agent.justine.analyze-intimacao
‚îÇ   ‚îú‚îÄ‚îÄ Span: llm.gemini-2.5-pro (analisar conte√∫do)
‚îÇ   ‚îú‚îÄ‚îÄ Span: llm.gemini-2.5-pro (identificar prazos)
‚îÇ   ‚îî‚îÄ‚îÄ Span: llm.gemini-2.5-pro (gerar tarefas)
```

## üîß Uso Avan√ßado

### Criar Spans Customizados

#### Com o Sistema Interno (Recomendado)

```typescript
import { startAgentSpan, endSpan, setAttribute, addEvent } from '@/lib/tracing';

// Criar span
const span = startAgentSpan('meu-agente', 'Meu Agente', {
  attributes: {
    'custom.key': 'value',
  },
});

// Adicionar atributos
setAttribute(span, 'processo.numero', '0001234-56.2024.5.01.0000');

// Adicionar eventos
addEvent(span, 'documento-processado', {
  'documento.tipo': 'intima√ß√£o',
  'documento.tamanho': '1024',
});

try {
  // Seu c√≥digo aqui
  const resultado = await processarAlgo();
  
  // Finalizar com sucesso
  await endSpan(span, 'ok');
} catch (error) {
  // Finalizar com erro
  await endSpan(span, 'error', error.message);
}
```

#### Com OpenTelemetry Direto

```typescript
import { withOtelSpan } from '@/lib/otel-integration';

const resultado = await withOtelSpan('minha-operacao', async (span) => {
  span.setAttribute('custom.key', 'value');
  span.addEvent('evento-importante');
  
  return await fazerAlgo();
}, {
  'component': 'meu-componente',
});
```

### Helpers Dispon√≠veis

#### Para Chamadas LLM

```typescript
import { traceLLMCall } from '@/lib/otel-integration';

const resposta = await traceLLMCall(
  'gemini-2.5-pro',
  'generateContent',
  async () => {
    return await chamarLLM(prompt);
  },
  {
    prompt: 'Meu prompt',
    temperature: 0.7,
    maxTokens: 1024,
  }
);
```

#### Para Opera√ß√µes de Agentes

```typescript
import { traceAgentOperation } from '@/lib/otel-integration';

const resultado = await traceAgentOperation(
  'harvey',
  'Harvey Specter',
  'analisar-estrategia',
  async () => {
    return await analisarEstrategia();
  },
  {
    'processo.id': processoId,
    'estrategia.tipo': 'ofensiva',
  }
);
```

#### Para Processamento de Documentos

```typescript
import { traceDocumentProcessing } from '@/lib/otel-integration';

const resultado = await traceDocumentProcessing(
  'intimacao',
  'int-123',
  'extract',
  async () => {
    return await extrairDados(intimacao);
  }
);
```

#### Para Busca Vetorial (Qdrant)

```typescript
import { traceVectorSearch } from '@/lib/otel-integration';

const resultados = await traceVectorSearch(
  'legal_docs',
  'similarity_search',
  async () => {
    return await qdrant.search(query);
  },
  {
    query: 'direito trabalhista',
    limit: 10,
    score_threshold: 0.7,
  }
);
```

## üìà Visualiza√ß√£o e An√°lise

### No AI Toolkit Trace Viewer

O Trace Viewer mostra:

1. **Timeline** - Linha do tempo de todas as opera√ß√µes
2. **Spans hier√°rquicos** - Visualiza√ß√£o em √°rvore de opera√ß√µes relacionadas
3. **Atributos** - Todos os metadados de cada span
4. **Eventos** - Marcos importantes durante a execu√ß√£o
5. **Dura√ß√£o** - Tempo de cada opera√ß√£o
6. **Status** - Sucesso, erro ou em andamento
7. **Filtros** - Por agente, tipo de opera√ß√£o, status, etc.

### An√°lises √öteis

- **Performance de agentes** - Quais agentes s√£o mais r√°pidos/lentos?
- **Consumo de tokens** - Quanto cada opera√ß√£o consome?
- **Taxas de erro** - Quais opera√ß√µes falham mais?
- **Gargalos** - Onde o sistema passa mais tempo?
- **Fluxos completos** - Rastrear uma intima√ß√£o do in√≠cio ao fim

## üêõ Troubleshooting

### Traces n√£o aparecem no Viewer

1. **Verificar se AI Toolkit Trace Viewer est√° aberto**
   - Abra via `Ctrl+Shift+P` ‚Üí `AI Toolkit: Open Trace Viewer`

2. **Verificar endpoint**
   - Console deve mostrar: `üìä [OpenTelemetry] Endpoint: http://localhost:4318/v1/traces`
   - Se diferente, configure `VITE_OTLP_ENDPOINT` no `.env.local`

3. **Verificar inicializa√ß√£o**
   - Console deve mostrar: `‚úÖ [OpenTelemetry] Inicializado com sucesso`
   - Se n√£o aparecer, verifique erros no console

4. **Verificar firewall/antiv√≠rus**
   - Alguns antiv√≠rus bloqueiam localhost:4318
   - Adicione exce√ß√£o se necess√°rio

### Erros de importa√ß√£o

Se encontrar erros como `Cannot find module '@opentelemetry/api'`:

```bash
# Limpar cache e reinstalar
rm -rf node_modules package-lock.json
npm install
```

### Performance degradada

Se notar lentid√£o:

1. **Reduzir frequ√™ncia de exporta√ß√£o** (aumentar `scheduledDelayMillis`)
2. **Desabilitar tracing em desenvolvimento** (temporariamente)
3. **Usar sampling** para enviar apenas X% dos traces

## üìö Refer√™ncias

- [OpenTelemetry Docs](https://opentelemetry.io/docs/)
- [AI Toolkit for VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)
- [OTLP Specification](https://opentelemetry.io/docs/specs/otlp/)
- [Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/)

## üéØ Pr√≥ximos Passos

### Curto Prazo
- [ ] Adicionar tracing em mais servi√ßos (DJEN, DataJud, Qdrant, etc.)
- [ ] Criar dashboard customizado com m√©tricas de agentes
- [ ] Implementar alertas baseados em traces

### M√©dio Prazo
- [ ] Integrar com Azure Monitor (produ√ß√£o)
- [ ] Configurar exporta√ß√£o para m√∫ltiplos backends
- [ ] Adicionar sampling inteligente baseado em carga

### Longo Prazo
- [ ] Machine Learning para detec√ß√£o de anomalias em traces
- [ ] Auto-tuning de agentes baseado em telemetria
- [ ] Correlation entre traces, logs e m√©tricas

## üí° Dicas

1. **Use tracing para debugging** - Ao investigar bugs, filtre traces por `traceId` para ver todo o fluxo
2. **Monitore tokens** - Acompanhe `llm.total_tokens` para otimizar custos
3. **Analise lat√™ncia** - Identifique opera√ß√µes lentas e otimize
4. **Rastreie erros** - Spans com status `error` indicam problemas
5. **Compare performance** - Use traces para A/B testing de prompts/estrat√©gias

---

**Documenta√ß√£o gerada automaticamente** | √öltima atualiza√ß√£o: 13/12/2025
