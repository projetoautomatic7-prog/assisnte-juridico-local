# Sentry AI Agents Monitoring - Guia Completo Atualizado ‚úÖ

Este documento descreve a integra√ß√£o OFICIAL do **Sentry AI Agents Monitoring** com o sistema Assistente Jur√≠dico PJe, seguindo as **pr√°ticas da documenta√ß√£o oficial** do Sentry (Dezembro 2025).

## üìã Resumo das Mudan√ßas

### O que mudou na v2.0.0?

| Aspecto | v1 (Antigo) | v2 (Novo - Oficial) |
|---------|-------------|---------------------|
| **Implementa√ß√£o** | Custom wrapper | Seguindo conven√ß√µes OpenTelemetry oficiais |
| **Op√ß√µes** | `includePrompts`, `captureErrors` | `recordInputs`, `recordOutputs` (padr√£o SDK) |
| **Spans** | Gen√©ricos | `gen_ai.invoke_agent`, `gen_ai.chat`, `gen_ai.execute_tool`, `gen_ai.handoff` |
| **Atributos** | Customizados | Seguindo spec OpenTelemetry (`gen_ai.*`) |
| **Integra√ß√£o** | Manual (wrapper functions) | Spans manuais + `googleGenAIIntegration()` (quando dispon√≠vel) |
| **Conversa√ß√£o** | N√£o suportada | `conversation.session_id`, `conversation.turn` |
| **Tool Calling** | N√£o suportado | `gen_ai.execute_tool` com input/output |
| **Handoff** | N√£o suportado | `gen_ai.handoff` entre agentes |

### Arquivos Novos

```
src/lib/sentry-gemini-integration-v2.ts  # ‚úÖ Nova implementa√ß√£o oficial
docs/SENTRY_AI_AGENTS_EXAMPLES.tsx       # ‚úÖ 6 exemplos pr√°ticos
docs/SENTRY_AI_MONITORING.md            # ‚úÖ Este guia
```

### Arquivos Mantidos (compatibilidade)

```
src/lib/sentry-gemini-integration.ts     # ‚ö†Ô∏è Legacy (n√£o remover ainda)
```

## üéØ Por que migrar para v2?

### Benef√≠cios da nova implementa√ß√£o:

1. **Compatibilidade** com dashboard oficial do Sentry AI Agents
2. **Padroniza√ß√£o** - Segue spec OpenTelemetry reconhecida pela ind√∫stria
3. **Mais m√©tricas** - Token usage, tool calls, handoffs, conversa√ß√£o
4. **Melhor an√°lise** - Queries e filtros mais poderosos no Sentry.io
5. **Futureproof** - Quando `googleGenAIIntegration()` estiver dispon√≠vel, migra√ß√£o f√°cil

## üìä Conven√ß√µes OpenTelemetry (Oficial)

### Tipos de Operations (op)

| op | Descri√ß√£o | Quando usar |
|----|-----------|-------------|
| `gen_ai.invoke_agent` | Invoca√ß√£o completa de agente | Rastrear agente do in√≠cio ao fim |
| `gen_ai.chat` | Chamada individual ao LLM | Cada request/response do modelo |
| `gen_ai.execute_tool` | Execu√ß√£o de ferramenta | Function calling, busca em KB, etc |
| `gen_ai.handoff` | Transfer√™ncia entre agentes | Quando um agente passa contexto para outro |

### Atributos Obrigat√≥rios

| Atributo | Tipo | Exemplo |
|----------|------|---------|
| `gen_ai.system` | string | `"gcp.gemini"`, `"openai"`, `"custom-llm"` |
| `gen_ai.request.model` | string | `"gemini-2.5-pro"`, `"gpt-4"` |
| `gen_ai.operation.name` | string | `"invoke_agent"`, `"chat"` |

### Atributos Opcionais (mas recomendados)

| Atributo | Tipo | Descri√ß√£o |
|----------|------|-----------|
| `gen_ai.agent.name` | string | Nome do agente (ex: "Harvey Specter") |
| `gen_ai.request.temperature` | float | 0.0 - 1.0 |
| `gen_ai.request.max_tokens` | int | Limite de tokens |
| `gen_ai.request.messages` | string | JSON stringified: `"[{role:'user',content:'...'}]"` |
| `gen_ai.response.text` | string | JSON stringified: `"['Resposta do LLM']"` |
| `gen_ai.usage.input_tokens` | int | Tokens de entrada (prompt) |
| `gen_ai.usage.output_tokens` | int | Tokens de sa√≠da (resposta) |
| `gen_ai.usage.total_tokens` | int | Total usado |
| `conversation.session_id` | string | ID √∫nico da conversa |
| `conversation.turn` | int | N√∫mero do turno (incrementa cada mensagem) |

## üîß Setup Inicial

### 1. Instalar depend√™ncias (j√° instaladas)

```bash
npm install @sentry/react@latest
```

### 2. Inicializar Sentry (`src/services/error-tracking.ts`)

```typescript
import * as Sentry from "@sentry/react";

Sentry.init({
  dsn: "https://<key>@<org>.ingest.sentry.io/<project>",
  
  // ‚ö†Ô∏è IMPORTANTE: Define se grava prompts/outputs
  // true = grava (√∫til dev), false = n√£o grava (LGPD prod)
  sendDefaultPii: process.env.NODE_ENV === "development",
  
  tracesSampleRate: process.env.NODE_ENV === "production" ? 0.1 : 1.0,
  
  integrations: [
    Sentry.browserTracingIntegration(),
    // googleGenAIIntegration() ainda n√£o dispon√≠vel em @sentry/react v10
    // Use spans manuais (createInvokeAgentSpan, etc)
  ],
});
```

### 3. Configurar op√ß√µes de PII

```typescript
import { setGeminiIntegrationOptions } from '@/lib/sentry-gemini-integration-v2';

// Produ√ß√£o: n√£o gravar prompts/outputs (LGPD)
if (process.env.NODE_ENV === "production") {
  setGeminiIntegrationOptions({
    recordInputs: false,
    recordOutputs: false
  });
}

// Desenvolvimento: gravar tudo para debug
else {
  setGeminiIntegrationOptions({
    recordInputs: true,
    recordOutputs: true
  });
}
```

## üíª Exemplos de Uso

### Exemplo 1: Invoke Agent Simples

```typescript
import { createInvokeAgentSpan } from '@/lib/sentry-gemini-integration-v2';

async function analisarIntimacao(expedienteId: string) {
  const result = await createInvokeAgentSpan(
    {
      agentName: "Mrs. Justin-e",
      system: "gcp.gemini",
      model: "gemini-2.5-pro",
      temperature: 0.7
    },
    {
      sessionId: `expediente_${expedienteId}`,
      turn: 1
    },
    async (span) => {
      // Chama Gemini API
      const response = await callGeminiAPI({
        prompt: "Analyze this legal intimation..."
      });
      
      // Atribui resposta ao span
      span?.setAttribute("gen_ai.response.text", JSON.stringify([response.text]));
      span?.setAttribute("gen_ai.usage.total_tokens", response.usage.totalTokens);
      span?.setAttribute("conversation.resolution_status", "resolved");
      
      return response;
    }
  );
  
  return result;
}
```

**Resultado no Sentry:**
- ‚úÖ Span com `op: gen_ai.invoke_agent`
- ‚úÖ Nome: `invoke_agent Mrs. Justin-e`
- ‚úÖ Dura√ß√£o, tokens, status
- ‚úÖ Aparece no AI Agents Dashboard

### Exemplo 2: Agente com Tool Calling

```typescript
import {
  createInvokeAgentSpan,
  createChatSpan,
  createExecuteToolSpan
} from '@/lib/sentry-gemini-integration-v2';

async function processarExpedienteComFerramentas(expediente: Expediente) {
  return createInvokeAgentSpan(
    {
      agentName: "Mrs. Justin-e",
      system: "gcp.gemini",
      model: "gemini-2.5-pro"
    },
    {
      sessionId: `exp_${expediente.id}`,
      turn: 1
    },
    async (agentSpan) => {
      // 1. LLM decide se precisa de ferramenta
      const llmResponse = await createChatSpan(
        { agentName: "Mrs. Justin-e", system: "gcp.gemini", model: "gemini-2.5-pro" },
        [{ role: "user", content: expediente.conteudo }],
        async (chatSpan) => {
          const response = await callGeminiAPI({ prompt: expediente.conteudo });
          chatSpan?.setAttribute("gen_ai.response.text", JSON.stringify([response.text]));
          
          if (response.toolCalls) {
            chatSpan?.setAttribute("gen_ai.response.tool_calls", JSON.stringify(response.toolCalls));
          }
          
          return response;
        }
      );
      
      // 2. Se houver tool calls, executa
      if (llmResponse.toolCalls) {
        for (const toolCall of llmResponse.toolCalls) {
          await createExecuteToolSpan(
            { agentName: "Mrs. Justin-e", system: "gcp.gemini", model: "gemini-2.5-pro" },
            {
              toolName: toolCall.name,
              toolType: "function",
              toolInput: JSON.stringify(toolCall.arguments)
            },
            async (toolSpan) => {
              const output = await executeTool(toolCall.name, toolCall.arguments);
              toolSpan?.setAttribute("gen_ai.tool.output", JSON.stringify(output));
              return output;
            }
          );
        }
      }
      
      // 3. Atributos finais do agente
      agentSpan?.setAttribute("gen_ai.response.text", llmResponse.text);
      agentSpan?.setAttribute("conversation.tools_used", llmResponse.toolCalls?.length || 0);
      
      return llmResponse;
    }
  );
}
```

### Exemplo 3: Handoff Entre Agentes

```typescript
import { createHandoffSpan } from '@/lib/sentry-gemini-integration-v2';

async function processarComHandoff(processo: Process) {
  // 1. Harvey analisa estrat√©gia
  const harveyDecision = await createInvokeAgentSpan(
    { agentName: "Harvey Specter", system: "gcp.gemini", model: "gemini-2.5-pro" },
    { sessionId: `proc_${processo.id}`, turn: 1 },
    async (span) => {
      const decision = await analyzeStrategy(processo);
      span?.setAttribute("gen_ai.response.text", JSON.stringify([decision.text]));
      return decision;
    }
  );
  
  // 2. Harvey decide transferir para Justin-e
  if (harveyDecision.needsIntimationAnalysis) {
    // Marca handoff
    await createHandoffSpan("Harvey Specter", "Mrs. Justin-e");
    
    // 3. Mrs. Justin-e assume
    const justinResult = await createInvokeAgentSpan(
      { agentName: "Mrs. Justin-e", system: "gcp.gemini", model: "gemini-2.5-pro" },
      { sessionId: `proc_${processo.id}`, turn: 2 },
      async (span) => {
        const analysis = await analyzeIntimation(processo);
        span?.setAttribute("gen_ai.response.text", JSON.stringify([analysis.text]));
        return analysis;
      }
    );
    
    return justinResult;
  }
  
  return harveyDecision;
}
```

### Exemplo 4: Hook React

```typescript
import { useAIInstrumentation } from '@/lib/sentry-gemini-integration-v2';
import { useState, useEffect } from 'react';

function ChatComponent() {
  const { invokeAgent } = useAIInstrumentation();
  const [sessionId, setSessionId] = useState("");
  const [messages, setMessages] = useState([]);
  
  useEffect(() => {
    // Client-side only para evitar hydration mismatch
    setSessionId(`session_${Date.now()}`);
  }, []);
  
  const handleSend = async (userMessage: string) => {
    const response = await invokeAgent(
      {
        agentName: "Legal Assistant",
        system: "gcp.gemini",
        model: "gemini-2.5-pro"
      },
      {
        sessionId,
        turn: messages.length + 1,
        messages: [
          { role: "system", content: "You are a legal assistant" },
          ...messages,
          { role: "user", content: userMessage }
        ]
      },
      async (span) => {
        const aiResponse = await callAIBackend(userMessage);
        
        span?.setAttribute("gen_ai.response.text", aiResponse.message);
        span?.setAttribute("gen_ai.usage.total_tokens", aiResponse.tokens);
        
        return aiResponse;
      }
    );
    
    setMessages([...messages, 
      { role: "user", content: userMessage },
      { role: "assistant", content: response.message }
    ]);
  };
  
  return <div>{/* UI */}</div>;
}
```

## üìà Monitoramento no Sentry.io

### Onde ver os dados

1. **AI Agents Dashboard**: https://sentry.io/orgredirect/organizations/:orgslug/insights/ai/agents/
2. **Traces Explorer**: https://sentry.io/orgredirect/organizations/:orgslug/explore/traces/
3. **Metrics**: https://sentry.io/orgredirect/organizations/:orgslug/explore/metrics/

### Queries √öteis

**Lat√™ncia m√©dia por agente:**
```
avg(span.duration) 
WHERE op:gen_ai.invoke_agent 
GROUP BY gen_ai.agent.name
```

**Total de tokens por modelo:**
```
sum(gen_ai.usage.total_tokens) 
WHERE op:gen_ai.chat 
GROUP BY gen_ai.request.model
```

**Taxa de erro por agente:**
```
count(*) WHERE op:gen_ai.invoke_agent AND status:error 
/ count(*) WHERE op:gen_ai.invoke_agent
GROUP BY gen_ai.agent.name
```

**Ferramentas mais usadas:**
```
count(*) 
WHERE op:gen_ai.execute_tool 
GROUP BY gen_ai.tool.name
```

## üîí LGPD e Seguran√ßa

### Configura√ß√£o Recomendada para Produ√ß√£o

```typescript
// src/services/error-tracking.ts

Sentry.init({
  dsn: "...",
  
  // ‚ùå N√£o gravar PII em produ√ß√£o
  sendDefaultPii: false,
  
  beforeSend(event) {
    // Filtra dados sens√≠veis
    if (event.contexts?.ai) {
      delete event.contexts.ai.prompt;
      delete event.contexts.ai.response;
    }
    return event;
  }
});

// Configurar op√ß√µes globais
setGeminiIntegrationOptions({
  recordInputs: false,   // ‚ùå N√£o grava prompts
  recordOutputs: false   // ‚ùå N√£o grava respostas
});
```

### O que voc√™ ainda ter√° (sem PII):

- ‚úÖ Lat√™ncia de todas as chamadas
- ‚úÖ Uso de tokens (input/output/total)
- ‚úÖ Nomes de agentes e modelos
- ‚úÖ Nomes de ferramentas executadas
- ‚úÖ Taxa de erro e sucesso
- ‚úÖ Traces completos (sem conte√∫do)

## üîÑ Migra√ß√£o v1 ‚Üí v2

### Antes (v1):

```typescript
import { instrumentGeminiCall } from '@/lib/sentry-gemini-integration';

const wrapper = instrumentGeminiCall(
  {
    model: "gemini-2.5-pro",
    operation: "generate_content",
    prompt: "Analyze this",
    startTime: Date.now()
  },
  { includePrompts: true, captureErrors: true }
);

const result = await wrapper(async () => {
  return await callGeminiAPI();
});
```

### Depois (v2):

```typescript
import { createInvokeAgentSpan } from '@/lib/sentry-gemini-integration-v2';

const result = await createInvokeAgentSpan(
  {
    agentName: "My Agent",
    system: "gcp.gemini",
    model: "gemini-2.5-pro"
  },
  { sessionId: "session_123", turn: 1 },
  async (span) => {
    const response = await callGeminiAPI();
    span?.setAttribute("gen_ai.response.text", response.text);
    span?.setAttribute("gen_ai.usage.total_tokens", response.tokens);
    return response;
  }
);
```

## ‚úÖ Checklist de Implementa√ß√£o (ATUALIZADO - Fase 3 Completa)

### Fase 1: Infraestrutura (100% Completo) ‚úÖ
- [x] ‚úÖ Criar `sentry-gemini-integration-v2.ts`
- [x] ‚úÖ Adicionar exemplos em `SENTRY_AI_AGENTS_EXAMPLES.tsx`
- [x] ‚úÖ Documentar em `SENTRY_AI_MONITORING.md`
- [x] ‚úÖ Criar schemas Zod (agent, expediente, process)
- [x] ‚úÖ Criar hooks validated (processes, expedientes, clientes, minutas)
- [x] ‚úÖ Implementar lazy loading em 14 componentes pesados
- [x] ‚úÖ Criar testes unit√°rios para schemas Zod (18 testes)

### Fase 2: Instrumenta√ß√£o Inicial (100% Completo) ‚úÖ
- [x] ‚úÖ Migrar agente `Harvey Specter` para v2
- [x] ‚úÖ Migrar agente `Mrs. Justin-e` para v2
- [x] ‚úÖ Instrumentar agente `Reda√ß√£o de Peti√ß√µes` com createChatSpan
- [x] ‚úÖ Instrumentar agente `Monitor DJEN` com createInvokeAgentSpan (corrigido)

### Fase 3: Instrumenta√ß√£o Avan√ßada (100% Completo) ‚úÖ
- [x] ‚úÖ Instrumentar agente `Gest√£o de Prazos`
- [x] ‚úÖ Instrumentar agente `An√°lise Documental` (com tool calling)
- [x] ‚úÖ Instrumentar agente `Pesquisa Jurisprudencial` (Chat + Tool)
- [x] ‚úÖ Instrumentar agente `An√°lise de Risco` (Chat com heur√≠sticas)
- [x] ‚úÖ Instrumentar agente `Estrat√©gia Processual` (Handoff + Chat)

### Fase 4: Instrumenta√ß√£o Final (Pendente)
- [ ] üîÑ Instrumentar agentes restantes (6/15 pendentes)
  - [ ] Comunica√ß√£o com Clientes
  - [ ] Revis√£o Contratual
  - [ ] Compliance
  - [ ] Organiza√ß√£o de Arquivos
  - [ ] An√°lise Financeira
  - [ ] Tradu√ß√£o Jur√≠dica
- [ ] üîÑ Configurar PII filtering para produ√ß√£o (LGPD)
- [ ] üîÑ Testar no dashboard AI Agents do Sentry.io
- [ ] üîÑ Criar alertas customizados
- [ ] üîÑ Documentar runbooks de troubleshooting

## üéØ Agentes Instrumentados (9/15 = 60%)

| Agente | Status | Arquivo | Padr√£o | Tool | Handoff |
|--------|--------|---------|--------|------|---------|
| Harvey Specter | ‚úÖ Completo | `HarveySpecterChat.tsx` | Agent + Chat | ‚ùå | ‚ùå |
| Mrs. Justin-e | ‚úÖ Completo | `use-autonomous-agents.ts` | Agent | ‚ùå | ‚ùå |
| Reda√ß√£o Peti√ß√µes | ‚úÖ Completo | `redacao_graph.ts`, `gemini-service.ts` | Agent + Chat | ‚ùå | ‚ùå |
| Monitor DJEN | ‚úÖ Completo | `monitor_graph.ts` | Agent | ‚ùå | ‚ùå |
| Gest√£o Prazos | ‚úÖ Completo | `gestao_prazos_graph.ts` | Agent | ‚ùå | ‚ùå |
| An√°lise Documental | ‚úÖ Completo | `analise_documental_graph.ts` | Agent | ‚úÖ entity_extraction | ‚ùå |
| Pesquisa Juris | ‚úÖ Completo | `pesquisa_graph.ts` | Agent + Chat | ‚úÖ search_db | ‚ùå |
| An√°lise de Risco | ‚úÖ Completo | `analise_risco_graph.ts` | Agent + Chat | ‚ùå | ‚ùå |
| **Estrat√©gia Processual** | ‚úÖ Completo | `estrategia_processual_graph.ts` | Agent + Chat | ‚ùå | ‚úÖ ‚Üí Risco |
| Comunica√ß√£o Clientes | ‚è∏Ô∏è Pendente | - | - | - | - |
| Revis√£o Contratual | ‚è∏Ô∏è Pendente | - | - | - | - |
| Compliance | ‚è∏Ô∏è Pendente | - | - | - | - |
| Organiza√ß√£o Arquivos | ‚è∏Ô∏è Pendente | - | - | - | - |
| An√°lise Financeira | ‚è∏Ô∏è Pendente | - | - | - | - |
| Tradu√ß√£o Jur√≠dica | ‚è∏Ô∏è Pendente | - | - | - | - |

## üéä Novidades da Fase 3

### ‚≠ê Handoff Entre Agentes (Primeira Implementa√ß√£o!)

**Exemplo: Estrat√©gia Processual ‚Üí An√°lise de Risco**

```typescript
// Detectar necessidade de an√°lise de risco
if (riskScore === undefined || riskScore === 0.5) {
  await createHandoffSpan("Estrat√©gia Processual", "An√°lise de Risco");
  
  span?.setAttribute("estrategia.handoff_triggered", true);
  span?.setAttribute("estrategia.handoff_reason", "Necess√°rio an√°lise de risco primeiro");
  
  // Aguardar an√°lise...
}
```

**No Sentry.io:**
- ‚úÖ Span com `op: gen_ai.handoff`
- ‚úÖ Atributos: `gen_ai.from_agent`, `gen_ai.to_agent`
- ‚úÖ Trace completo mostrando fluxo entre agentes

### üîß Tool Calling em Produ√ß√£o

**Agente: An√°lise Documental**

```typescript
const entities = await createExecuteToolSpan(
  { agentName: "An√°lise Documental", ... },
  {
    toolName: "entity_extraction",
    toolType: "function",
    toolInput: JSON.stringify({ texto, tipo })
  },
  async (toolSpan) => {
    const result = await extractEntities(texto);
    toolSpan?.setAttribute("gen_ai.tool.output", JSON.stringify(result));
    return result;
  }
);
```

**Sa√≠da:**
```json
{
  "partes": ["Autor: Jo√£o Silva", "R√©u: Empresa XYZ"],
  "datas": ["2024-12-08", "2024-11-15"],
  "valores": ["R$ 10.000,00"],
  "processos": ["1234567-89.2024.5.02.0999"]
}
```

**Agente: Pesquisa Jurisprudencial**

```typescript
// 1. Chat LLM para gerar query
const query = await createChatSpan(...);

// 2. Tool para buscar em datastore
const resultados = await createExecuteToolSpan(
  {...},
  {
    toolName: "search_jurisprudence_database",
    toolType: "datastore",
    toolInput: JSON.stringify({ query, limit: 10 })
  },
  async (toolSpan) => {
    const precedentes = await searchDatabase(query);
    toolSpan?.setAttribute("search.results_count", precedentes.length);
    return precedentes;
  }
);
```

### üìä An√°lise de Risco com Heur√≠sticas

**F√≥rmula de C√°lculo:**

```typescript
let riskScore = 0.5; // Baseline

// Ajustar por complexidade
if (complexidade === "baixa") riskScore -= 0.15;
else if (complexidade === "alta") riskScore += 0.2;

// Ajustar por precedentes
if (precedentes.length > 3) riskScore -= 0.1;
else if (precedentes.length === 0) riskScore += 0.15;

// Ajustar por valor da causa
if (valorCausa > 100000) riskScore += 0.1;

// Limitar entre 0 e 1
riskScore = Math.max(0, Math.min(1, riskScore));
```

**Classifica√ß√£o:**
- `score < 0.3` ‚Üí **Risco Baixo**
- `0.3 ‚â§ score < 0.6` ‚Üí **Risco M√©dio**
- `score ‚â• 0.6` ‚Üí **Risco Alto**

**Probabilidade de Sucesso:**
```typescript
probabilidadeSucesso = (1 - riskScore) * 100
```

### üéØ Estrat√©gias Contextuais

| Fase | Risco | Estrat√©gia Principal | A√ß√µes Imediatas |
|------|-------|---------------------|-----------------|
| Inicial | Baixo | Contesta√ß√£o completa | Juntar docs, Arrolar testemunhas |
| Inicial | Alto | Acordo pr√©-processual | Negocia√ß√£o, An√°lise de valores |
| Recursal | Baixo | Recurso de apela√ß√£o | Analisar senten√ßa, Preparar minuta |
| Recursal | Alto | Acordo judicial | Proposta redu√ß√£o, An√°lise custo-benef√≠cio |

---

**√öltima atualiza√ß√£o:** Dezembro 2025  
**Vers√£o:** 2.0.0 (Migra√ß√£o para padr√µes oficiais OpenTelemetry)
