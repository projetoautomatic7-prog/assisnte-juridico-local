spec:
  inputs:
    stage:
      default: backup
      description: "Stage onde o backup ser√° executado"
    backup_type:
      default: "database"
      description: "Tipo de backup: database, files, documents, all"
      options: ["database", "files", "documents", "all"]
    database_type:
      default: "postgresql"
      description: "Tipo de banco de dados: postgresql, mysql, mongodb"
      options: ["postgresql", "mysql", "mongodb"]
    database_host:
      description: "Host do banco de dados"
    database_port:
      default: "5432"
      description: "Porta do banco de dados"
    database_name:
      description: "Nome do banco de dados"
    database_user:
      description: "Usu√°rio do banco de dados"
    database_password:
      description: "Senha do banco de dados"
    s3_bucket:
      description: "Bucket S3 para armazenar backups"
    s3_region:
      default: "us-east-1"
      description: "Regi√£o do S3"
    retention_days:
      default: "30"
      description: "Dias para reten√ß√£o de backups"
    compression:
      default: true
      description: "Comprimir arquivos de backup"
    encryption:
      default: true
      description: "Criptografar backups"
    include_sensitive_data:
      default: false
      description: "Incluir dados sens√≠veis no backup (dados pessoais, etc.)"
    notify_on_completion:
      default: true
      description: "Notificar quando backup for conclu√≠do"

# Componente de Backup para Dados Jur√≠dicos
# Suporte a backup de banco de dados, arquivos e documentos
# Com criptografia e compress√£o autom√°tica

database-backup:
  stage: $[[ inputs.stage ]]
  image: alpine:latest
  before_script:
    - apk add --no-cache postgresql-client mysql-client mongodb-tools aws-cli gzip openssl
  script:
    - echo "üíæ Iniciando backup de banco de dados..."
    - |
      # Configurar timestamp
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      BACKUP_NAME="${CI_PROJECT_NAME}_${CI_COMMIT_BRANCH}_${TIMESTAMP}"
      BACKUP_DIR="/tmp/backup_$TIMESTAMP"
      mkdir -p "$BACKUP_DIR"

      # Backup baseado no tipo de banco
      case "$[[ inputs.database_type ]]" in
        postgresql)
          echo "üìä Fazendo backup PostgreSQL..."
          export PGPASSWORD="$[[ inputs.database_password ]]"
          pg_dump \
            -h "$[[ inputs.database_host ]]" \
            -p "$[[ inputs.database_port ]]" \
            -U "$[[ inputs.database_user ]]" \
            -d "$[[ inputs.database_name ]]" \
            -f "$BACKUP_DIR/database.sql" \
            --no-owner --no-privileges --clean --if-exists
          ;;
        mysql)
          echo "üìä Fazendo backup MySQL..."
          mysqldump \
            -h "$[[ inputs.database_host ]]" \
            -P "$[[ inputs.database_port ]]" \
            -u "$[[ inputs.database_user ]]" \
            -p"$[[ inputs.database_password ]]" \
            "$[[ inputs.database_name ]]" \
            > "$BACKUP_DIR/database.sql"
          ;;
        mongodb)
          echo "üìä Fazendo backup MongoDB..."
          mongodump \
            --host "$[[ inputs.database_host ]]" \
            --port "$[[ inputs.database_port ]]" \
            --username "$[[ inputs.database_user ]]" \
            --password "$[[ inputs.database_password ]]" \
            --db "$[[ inputs.database_name ]]" \
            --out "$BACKUP_DIR/mongodb_dump"
          ;;
        *)
          echo "‚ùå Tipo de banco n√£o suportado: $[[ inputs.database_type ]]"
          exit 1
          ;;
      esac

      # Verificar se backup foi criado
      if [ ! -e "$BACKUP_DIR" ]; then
        echo "‚ùå Falha ao criar backup"
        exit 1
      fi

      # Compress√£o
      if [ "$[[ inputs.compression ]]" = "true" ]; then
        echo "üóúÔ∏è  Comprimindo backup..."
        tar -czf "$BACKUP_DIR.tar.gz" -C "$BACKUP_DIR" .
        BACKUP_FILE="$BACKUP_DIR.tar.gz"
      else
        BACKUP_FILE="$BACKUP_DIR"
      fi

      # Criptografia
      if [ "$[[ inputs.encryption ]]" = "true" ]; then
        echo "üîê Criptografando backup..."
        openssl enc -aes-256-cbc -salt -in "$BACKUP_FILE" -out "$BACKUP_FILE.enc" -k "$BACKUP_ENCRYPTION_KEY"
        BACKUP_FILE="$BACKUP_FILE.enc"
      fi

      # Upload para S3
      if [ -n "$[[ inputs.s3_bucket ]]" ]; then
        echo "‚òÅÔ∏è  Enviando backup para S3..."
        aws configure set aws_access_key_id "$AWS_ACCESS_KEY_ID"
        aws configure set aws_secret_access_key "$AWS_SECRET_ACCESS_KEY"
        aws configure set region "$[[ inputs.s3_region ]]"

        S3_KEY="backups/$BACKUP_NAME$(basename "$BACKUP_FILE")"
        aws s3 cp "$BACKUP_FILE" "s3://$[[ inputs.s3_bucket ]]/$S3_KEY"

        # Configurar lifecycle para reten√ß√£o
        if [ "$[[ inputs.retention_days ]]" -gt 0 ]; then
          aws s3api put-bucket-lifecycle-configuration \
            --bucket "$[[ inputs.s3_bucket ]]" \
            --lifecycle-configuration '{
              "Rules": [
                {
                  "ID": "BackupRetention",
                  "Status": "Enabled",
                  "Prefix": "backups/",
                  "Expiration": {
                    "Days": '$[[ inputs.retention_days ]]'
                  }
                }
              ]
            }'
        fi

        echo "‚úÖ Backup enviado para S3: s3://$[[ inputs.s3_bucket ]]/$S3_KEY"
      else
        echo "‚ö†Ô∏è  S3 n√£o configurado, backup local mantido em $BACKUP_FILE"
      fi

      # Limpar arquivos tempor√°rios
      rm -rf "$BACKUP_DIR"

      echo "‚úÖ Backup conclu√≠do com sucesso!"
  artifacts:
    reports:
      dotenv: backup.env
    expire_in: 1 week
  allow_failure: false
  rules:
    - if: $CI_COMMIT_BRANCH && ($[[ inputs.backup_type ]] == "database" || $[[ inputs.backup_type ]] == "all")
    - when: manual

files-backup:
  stage: $[[ inputs.stage ]]
  image: alpine:latest
  before_script:
    - apk add --no-cache aws-cli gzip openssl
  script:
    - echo "üìÅ Iniciando backup de arquivos..."
    - |
      # Configurar timestamp
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      BACKUP_NAME="${CI_PROJECT_NAME}_files_${CI_COMMIT_BRANCH}_${TIMESTAMP}"
      BACKUP_DIR="/tmp/files_backup_$TIMESTAMP"
      mkdir -p "$BACKUP_DIR"

      # Copiar arquivos importantes
      echo "üìã Copiando arquivos do projeto..."
      cp -r public/ "$BACKUP_DIR/" 2>/dev/null || echo "‚ö†Ô∏è  Diret√≥rio public n√£o encontrado"
      cp -r docs/ "$BACKUP_DIR/" 2>/dev/null || echo "‚ö†Ô∏è  Diret√≥rio docs n√£o encontrado"
      cp -r src/ "$BACKUP_DIR/" 2>/dev/null || echo "‚ö†Ô∏è  Diret√≥rio src n√£o encontrado"

      # Arquivos de configura√ß√£o (excluindo sens√≠veis)
      mkdir -p "$BACKUP_DIR/config"
      cp package.json "$BACKUP_DIR/config/" 2>/dev/null || echo "‚ö†Ô∏è  package.json n√£o encontrado"
      cp tsconfig.json "$BACKUP_DIR/config/" 2>/dev/null || echo "‚ö†Ô∏è  tsconfig.json n√£o encontrado"
      cp tailwind.config.js "$BACKUP_DIR/config/" 2>/dev/null || echo "‚ö†Ô∏è  tailwind.config.js n√£o encontrado"

      # Excluir dados sens√≠veis se solicitado
      if [ "$[[ inputs.include_sensitive_data ]]" = "false" ]; then
        echo "üõ°Ô∏è  Removendo dados sens√≠veis..."
        find "$BACKUP_DIR" -name "*.env*" -delete
        find "$BACKUP_DIR" -name "*secret*" -delete
        find "$BACKUP_DIR" -name "*key*" -delete
        rm -f "$BACKUP_DIR/config/.env"
      fi

      # Compress√£o
      if [ "$[[ inputs.compression ]]" = "true" ]; then
        echo "üóúÔ∏è  Comprimindo arquivos..."
        tar -czf "$BACKUP_DIR.tar.gz" -C "$BACKUP_DIR" .
        BACKUP_FILE="$BACKUP_DIR.tar.gz"
      else
        BACKUP_FILE="$BACKUP_DIR"
      fi

      # Criptografia
      if [ "$[[ inputs.encryption ]]" = "true" ]; then
        echo "üîê Criptografando backup..."
        openssl enc -aes-256-cbc -salt -in "$BACKUP_FILE" -out "$BACKUP_FILE.enc" -k "$BACKUP_ENCRYPTION_KEY"
        BACKUP_FILE="$BACKUP_FILE.enc"
      fi

      # Upload para S3
      if [ -n "$[[ inputs.s3_bucket ]]" ]; then
        echo "‚òÅÔ∏è  Enviando backup para S3..."
        aws configure set aws_access_key_id "$AWS_ACCESS_KEY_ID"
        aws configure set aws_secret_access_key "$AWS_SECRET_ACCESS_KEY"
        aws configure set region "$[[ inputs.s3_region ]]"

        S3_KEY="backups/$BACKUP_NAME$(basename "$BACKUP_FILE")"
        aws s3 cp "$BACKUP_FILE" "s3://$[[ inputs.s3_bucket ]]/$S3_KEY"

        echo "‚úÖ Backup de arquivos enviado para S3: s3://$[[ inputs.s3_bucket ]]/$S3_KEY"
      else
        echo "‚ö†Ô∏è  S3 n√£o configurado, backup local mantido em $BACKUP_FILE"
      fi

      # Limpar arquivos tempor√°rios
      rm -rf "$BACKUP_DIR"

      echo "‚úÖ Backup de arquivos conclu√≠do!"
  artifacts:
    reports:
      dotenv: backup.env
    expire_in: 1 week
  allow_failure: false
  rules:
    - if: $CI_COMMIT_BRANCH && ($[[ inputs.backup_type ]] == "files" || $[[ inputs.backup_type ]] == "all")
    - when: manual

documents-backup:
  stage: $[[ inputs.stage ]]
  image: alpine:latest
  before_script:
    - apk add --no-cache aws-cli gzip openssl
  script:
    - echo "üìÑ Iniciando backup de documentos jur√≠dicos..."
    - |
      # Configurar timestamp
      TIMESTAMP=$(date +%Y%m%d_%H%M%S)
      BACKUP_NAME="${CI_PROJECT_NAME}_documents_${CI_COMMIT_BRANCH}_${TIMESTAMP}"
      BACKUP_DIR="/tmp/documents_backup_$TIMESTAMP"
      mkdir -p "$BACKUP_DIR"

      # Copiar documentos jur√≠dicos
      echo "üìã Copiando documentos jur√≠dicos..."
      cp -r docs/ "$BACKUP_DIR/" 2>/dev/null || echo "‚ö†Ô∏è  Diret√≥rio docs n√£o encontrado"

      # Documentos espec√≠ficos do projeto jur√≠dico
      mkdir -p "$BACKUP_DIR/legal"
      cp PRD.md "$BACKUP_DIR/legal/" 2>/dev/null || echo "‚ö†Ô∏è  PRD.md n√£o encontrado"
      cp README.md "$BACKUP_DIR/legal/" 2>/dev/null || echo "‚ö†Ô∏è  README.md n√£o encontrado"
      cp LICENSE "$BACKUP_DIR/legal/" 2>/dev/null || echo "‚ö†Ô∏è  LICENSE n√£o encontrado"

      # Backup de configura√ß√µes legais
      mkdir -p "$BACKUP_DIR/legal-config"
      cp docs/DJEN_DOCUMENTATION.md "$BACKUP_DIR/legal-config/" 2>/dev/null || echo "‚ö†Ô∏è  DJEN_DOCUMENTATION.md n√£o encontrado"
      cp docs/SECURITY.md "$BACKUP_DIR/legal-config/" 2>/dev/null || echo "‚ö†Ô∏è  SECURITY.md n√£o encontrado"

      # Excluir dados sens√≠veis
      echo "üõ°Ô∏è  Removendo dados sens√≠veis dos documentos..."
      find "$BACKUP_DIR" -name "*.env*" -delete
      find "$BACKUP_DIR" -name "*secret*" -delete
      find "$BACKUP_DIR" -name "*credential*" -delete

      # Compress√£o
      if [ "$[[ inputs.compression ]]" = "true" ]; then
        echo "üóúÔ∏è  Comprimindo documentos..."
        tar -czf "$BACKUP_DIR.tar.gz" -C "$BACKUP_DIR" .
        BACKUP_FILE="$BACKUP_DIR.tar.gz"
      else
        BACKUP_FILE="$BACKUP_DIR"
      fi

      # Criptografia obrigat√≥ria para documentos jur√≠dicos
      echo "üîê Criptografando documentos jur√≠dicos..."
      openssl enc -aes-256-cbc -salt -in "$BACKUP_FILE" -out "$BACKUP_FILE.enc" -k "$LEGAL_BACKUP_ENCRYPTION_KEY"
      BACKUP_FILE="$BACKUP_FILE.enc"

      # Upload para S3
      if [ -n "$[[ inputs.s3_bucket ]]" ]; then
        echo "‚òÅÔ∏è  Enviando documentos para S3..."
        aws configure set aws_access_key_id "$AWS_ACCESS_KEY_ID"
        aws configure set aws_secret_access_key "$AWS_SECRET_ACCESS_KEY"
        aws configure set region "$[[ inputs.s3_region ]]"

        S3_KEY="legal-backups/$BACKUP_NAME$(basename "$BACKUP_FILE")"
        aws s3 cp "$BACKUP_FILE" "s3://$[[ inputs.s3_bucket ]]/$S3_KEY"

        # Configurar lifecycle com reten√ß√£o mais longa para documentos legais
        RETENTION_DAYS=$(( $[[ inputs.retention_days ]] > 365 ? $[[ inputs.retention_days ]] : 365 ))
        aws s3api put-bucket-lifecycle-configuration \
          --bucket "$[[ inputs.s3_bucket ]]" \
          --lifecycle-configuration '{
            "Rules": [
              {
                "ID": "LegalDocumentsRetention",
                "Status": "Enabled",
                "Prefix": "legal-backups/",
                "Expiration": {
                  "Days": '$RETENTION_DAYS'
                }
              }
            ]
          }'

        echo "‚úÖ Documentos jur√≠dicos enviados para S3: s3://$[[ inputs.s3_bucket ]]/$S3_KEY"
      else
        echo "‚ö†Ô∏è  S3 n√£o configurado, backup local mantido em $BACKUP_FILE"
      fi

      # Limpar arquivos tempor√°rios
      rm -rf "$BACKUP_DIR"

      echo "‚úÖ Backup de documentos jur√≠dicos conclu√≠do!"
  artifacts:
    reports:
      dotenv: backup.env
    expire_in: 1 week
  allow_failure: false
  rules:
    - if: $CI_COMMIT_BRANCH && ($[[ inputs.backup_type ]] == "documents" || $[[ inputs.backup_type ]] == "all")
    - when: manual