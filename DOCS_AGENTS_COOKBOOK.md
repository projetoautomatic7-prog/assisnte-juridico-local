# ðŸŽ¯ Sistema de Agentes - AnÃ¡lise OpenAI Cookbook

## âœ… Implementado (Prioridade 1)

### 1. Sistema de AvaliaÃ§Ã£o (Evaluation System)
**Fonte:** `examples/evaluation/Building_resilient_prompts_using_an_evaluation_flywheel.md`

**Conceito:** Evaluation Flywheel - Ciclo contÃ­nuo de melhoria
- **Analyze:** Identificar padrÃµes de erro (open coding â†’ axial coding)
- **Measure:** Quantificar com graders automatizados
- **Improve:** Ajustar prompts e sistema

**ImplementaÃ§Ã£o:** `backend/src/services/agent-evaluator.ts`

#### Graders Implementados:
1. **Formatting Grader** - Valida formato (JSON/Markdown/Plain)
2. **Hallucination Grader** - Detecta alucinaÃ§Ãµes vs Ground Truth
3. **Completeness Grader** - Verifica elementos obrigatÃ³rios
4. **LLM-as-a-Judge** - AvaliaÃ§Ã£o geral de qualidade (0-10)

#### Categorias de Erro:
- `HALLUCINATION` - InformaÃ§Ãµes inventadas
- `FORMATTING` - Formato incorreto
- `INCOMPLETE` - Falta elementos
- `INCORRECT_INFO` - InformaÃ§Ã£o errada
- `CONTEXT_MISS` - Contexto ignorado
- `LEGAL_ERROR` - Erro jurÃ­dico especÃ­fico

#### API:
```bash
POST /api/evaluation/evaluate
{
  "agentId": "harvey-specter",
  "input": "Solicito anÃ¡lise de contrato X",
  "output": "AnÃ¡lise: ...",
  "groundTruth": "InformaÃ§Ã£o correta base", // opcional
  "requiredElements": ["conclusÃ£o", "fundamentos"], // opcional
  "expectedFormat": "markdown" // opcional
}

Resposta:
{
  "success": true,
  "evaluation": {
    "taskId": "task_123",
    "agentId": "harvey-specter",
    "score": 8,
    "passed": true,
    "errorCategories": [],
    "feedback": "Resposta clara e completa...",
    "timestamp": 1234567890,
    "evaluatorType": "llm"
  }
}
```

---

## ðŸ“‹ PrÃ³ximas ImplementaÃ§Ãµes (Prioridade 2)

### 2. Structured Outputs Multi-Agent
**Fonte:** `examples/Structured_outputs_multi_agent.ipynb`

**Conceito:** SaÃ­das estruturadas com JSON Schema + mÃºltiplos agentes

**Notebook:** 66 cÃ©lulas (18 code, 48 markdown)

**Bibliotecas:** 
- `openai`
- `pydantic` (validaÃ§Ã£o)
- `json`

**AplicaÃ§Ã£o:**
- Garantir formato consistente entre agentes
- ValidaÃ§Ã£o automÃ¡tica com schemas
- Facilitar handoffs estruturados

---

## ðŸ” Sistemas Adicionais Identificados

### 3. Entity Extraction for Long Documents
**Fonte:** `examples/Entity_extraction_for_long_documents.ipynb`

**Conceito:** ExtraÃ§Ã£o de entidades em documentos longos com sliding window

**AplicaÃ§Ã£o JurÃ­dica:**
- Extrair partes, datas, valores de petiÃ§Ãµes extensas
- Processar documentos acima do limite de contexto
- Manter consistÃªncia com validaÃ§Ã£o cruzada

---

### 4. Custom LLM-as-a-Judge
**Fonte:** `examples/evaluation/Custom-LLM-as-a-Judge.ipynb`

**Conceito:** LLM especializado para avaliar outputs

**Implementado parcialmente em:** `gradeLLMAsJudge()` (agent-evaluator.ts)

**Melhorias Pendentes:**
- Customizar critÃ©rios jurÃ­dicos especÃ­ficos
- CalibraÃ§Ã£o com exemplos gold standard
- MÃ©tricas agregadas (Cohen's Kappa, F1)

---

### 5. Hallucination Guardrails (Completo)
**Fonte:** `examples/Developing_hallucination_guardrails.ipynb`

**Conceito:** Precision/Recall para detectar alucinaÃ§Ãµes

**Implementado em:** `gradeHallucination()` (agent-evaluator.ts)

**MÃ©tricas:**
- **Precision:** Quantos dos positivos detectados sÃ£o reais?
- **Recall:** Quantos dos reais foram detectados?
- **Confidence:** 0.0-1.0 (usado threshold 0.7)

---

## ðŸ› ï¸ Arquitetura Atual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ORCHESTRATOR                               â”‚
â”‚  (LangGraph + Handoffs)                                     â”‚
â”‚                                                             â”‚
â”‚  1. selectInitialAgent() â”€â”€â”€â”€â”€> LLM escolhe agente         â”‚
â”‚  2. executeAgent() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Executa agente            â”‚
â”‚  3. decideHandoff() â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> LLM decide prÃ³ximo        â”‚
â”‚  4. Loop atÃ© conclusÃ£o                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  EVALUATOR (NOVO)                           â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Formatting      â”‚  â”‚ Hallucination    â”‚                â”‚
â”‚  â”‚ Grader          â”‚  â”‚ Grader           â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Completeness    â”‚  â”‚ LLM-as-a-Judge   â”‚                â”‚
â”‚  â”‚ Grader          â”‚  â”‚                  â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                             â”‚
â”‚  Score: 0-10 | Passed: boolean | ErrorCategories: []       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  15 AGENTES     â”‚
              â”‚  ESPECIALIZADOS â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Š Evaluation Flywheel

```
1. ANALYZE
   â”œâ”€ Coletar exemplos de falhas
   â”œâ”€ Open Coding: identificar problemas Ãºnicos
   â””â”€ Axial Coding: agrupar em categorias

2. MEASURE
   â”œâ”€ Criar graders automatizados
   â”œâ”€ Definir thresholds (ex: score >= 7 = pass)
   â””â”€ Executar em batch

3. IMPROVE
   â”œâ”€ Ajustar system prompts
   â”œâ”€ Adicionar few-shot examples
   â””â”€ Refinar instruÃ§Ãµes
```

---

## ðŸŽ¯ PrÃ³ximos Passos

### Imediato:
- [x] Implementar Evaluation System
- [x] Criar API `/api/evaluation/evaluate`
- [x] Integrar com agentes existentes

### Curto Prazo (Prioridade 2):
- [ ] Implementar Structured Outputs (JSON Schema)
- [ ] Adicionar Pydantic validation layer
- [ ] Integrar structured outputs com handoffs

### MÃ©dio Prazo:
- [ ] Entity Extraction para processos longos
- [ ] Custom LLM Judge jurÃ­dico especializado
- [ ] PersistÃªncia de histÃ³rico de avaliaÃ§Ãµes (PostgreSQL)

### Longo Prazo:
- [ ] CalibraÃ§Ã£o com dataset jurÃ­dico gold standard
- [ ] MÃ©tricas agregadas (Cohen's Kappa, Inter-rater reliability)
- [ ] Dashboard de anÃ¡lise de qualidade dos agentes

---

## ðŸ“š ReferÃªncias

- OpenAI Cookbook: `./openai-cookbook/examples/`
- Evaluation Flywheel: `evaluation/Building_resilient_prompts_using_an_evaluation_flywheel.md`
- Hallucination Guardrails: `Developing_hallucination_guardrails.ipynb`
- Structured Outputs: `Structured_outputs_multi_agent.ipynb`
- Entity Extraction: `Entity_extraction_for_long_documents.ipynb`
- Custom Judge: `evaluation/Custom-LLM-as-a-Judge.ipynb`

---

**Status Atual:** âœ… Prioridade 1 implementada | PrÃ³ximo: Prioridade 2 (Structured Outputs)

